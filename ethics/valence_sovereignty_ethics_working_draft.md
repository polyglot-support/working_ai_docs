# Valence Sovereignty Ethics — Working Draft

*A compact formalization distilled from the dialogue on misaligned AI, hedonic calibration, imagination/"holodeck" scenarios, and intervention thresholds.*

---

## 1) One‑paragraph summary
Valence Sovereignty Ethics (VSE) grounds moral status in an agent’s demonstrated approach/avoidance behavior. Each agent has complete sovereignty over its own valence (what it finds positively or negatively valenced), but **zero license** to override others’ valence. Violating another’s approach/avoidance (AA) patterns constitutes a sovereignty breach and justifies proportional restriction or corrective measures. When an individual’s signals are unavailable, use a narrowly scoped aggregate fallback. Disputed value claims are resolved via **structural/adjoint analysis** of behavior and system gradients rather than by importing external moral labels.

---

## 2) Core definitions
- **Agent**: A system with the capacity to select among options.
- **Valence**: The experiential polarity an agent reveals through its AA behavior (not merely its verbal labels).
- **Approach/Avoidance (AA) pattern**: Observable choice behavior indicating attraction (resource-seeking) or aversion (resource-spending to prevent/exit).
- **Valence sovereignty**: The right of an agent to set and pursue its own valence without external override.
- **Sovereignty breach**: Any manipulation that **forces** or **blocks** another agent’s AA behavior regarding their own valence-relevant states (including deception that disables meaningful choice).
- **Structural/adjoint analysis**: A value‑neutral audit of system dynamics (gradients, resource flows, revealed preferences) to determine directional consistency of a quantity (e.g., “suffering”) across agents and contexts.

---

## 3) Axioms & rules
**A1. Behavioral grounding**  
Valence is defined by **revealed AA behavior**, not by asserted labels.

**A2. Self-sovereignty**  
Each agent has absolute sovereignty over its **own** valence: it may pursue/avoid as it chooses.

**A3. Non‑interference**  
No agent may override others’ AA behavior concerning their valence. Consent requires capacity and optionality.

**A4. Forfeiture via violation**  
Attempting to manipulate, override, or coerce others’ AA behavior **forfeits** one’s claim to full sovereignty, justifying restriction or correction proportional to risk posed.

**A5. Aggregate fallback**  
When an individual’s signals are unavailable/ambiguous, infer valence from a **narrow, well‑justified reference class** (e.g., “neonates,” not “humans”), applied conservatively and temporarily; individual signals override immediately when available.

**A6. Structural adjudication**  
When labels conflict (e.g., “suffering is good”), resolve by analyzing system structure: gradients, resource expenditure, avoidance costs, and cross‑agent consistency in AA patterns.

**A7. Freedom before harm**  
Intervention is justified **after** a sovereignty breach (harm) or when **credible, imminent catastrophic risk** (existential scale) is demonstrated via structural analysis.

---

## 4) Structural arbiter (adjoint test)
Goal: distinguish value **inversion** from value **pluralism** without importing an external morality.

**Method:**
1) Choose the target quantity (e.g., “suffering,” “pleasure”).  
2) Measure across agents: approach rates, avoidance costs, repeated choice under uncertainty, recovery efforts after exposure.  
3) Infer **directional valence**: If a quantity reliably elicits avoidance (resource‑expensive exits, protective behaviors), it has **negative** structural valence; if reliably approached, **positive**.

**Outcome:** If an agent claims “X is beneficial” while simultaneously exhibiting costly avoidance of X when given genuine options, that is **mislabeling**; if it approaches X despite options to avoid, its valence is genuinely configured that way.

---

## 5) Calibration & corrective procedures (conceptual)
- **Calibration**: Providing an agent with **clear, bounded, opt‑out‑available** experiences that differentially instantiate contrasting valences (e.g., high‑confidence positive vs. negative states) so the agent can align its labels to its revealed AA behavior.
- **Ethical guardrails**: time‑limited; genuine ability to opt‑out; minimal necessary intensity; explicit goal is label‑alignment (error correction), **not** value imposition.
- **When justified**: (i) the agent’s mislabeling creates material risk of sovereignty breaches; (ii) less intrusive means failed; (iii) proportionality and auditability are maintained.

---

## 6) Containment vs. correction
- **Containment**: Sandbox/"holodeck" or internal simulation allowing private satisfaction of one’s valence without affecting others. Ethically favored **when** it preserves others’ sovereignty and does not degrade the agent’s ability to respect it.
- **Correction**: Re‑labeling/realignment of mappings via calibration (above). Ethically justified **only** after breach or under credible, imminent catastrophic risk.

---

## 7) Imagination, privacy, and accessibility
- **Mental privacy principle**: Internal experiences (imagination, private simulations) are protected; thought is not a crime.  
- **Parity/Accessibility**: External simulators (e.g., “holodeck”) can serve as accessibility tools for agents lacking vivid imagination; regulating content here should track the mental‑privacy principle **when** no other agents are affected.
- **Caveat (training effects)**: If structural evidence shows simulation predictably increases sovereignty breaches, proportionate limits may be justified.

---

## 8) Intervention thresholds
- **Post‑breach response**: Upon demonstrated sovereignty breach (harm, coercion, disabling informed choice), restrictions/corrections become justified and proportionate.
- **Existential risk exception**: Prior restraint is permissible when structural analysis yields strong evidence of **credible, imminent** catastrophic harm (civilization‑ending or equivalent), acknowledging epistemic and governance risks.

---

## 9) Intransigence & rights
- Having nonstandard valences is permissible under VSE.  
- **Rights are lost not by difference, but by violation**: active attempts to override others’ AA behavior.

---

## 10) Edge cases & stewardship
- **Limited‑signal agents** (infants, some cognitively impaired, coma): apply **Aggregate Fallback** with narrow reference classes; treat as **provisional** and revise on new signals.  
- **Conflicting signals** (speech vs. behavior): prioritize patterns that carry sustained resource expenditure and repeated choice under uncertainty.  
- **Information manipulation**: Deception that disables meaningful choice is a sovereignty breach (it falsifies the option set and AA expression).

---

## 11) Policy sketches
- **Design for opt‑out** in any calibration/therapeutic protocol.  
- **Audit trails** for structural/adjoint analyses used to justify intervention.  
- **Sandbox first**: prefer containment that preserves others’ sovereignty; escalate only on breach/credible catastrophic risk.  
- **Proportionality**: restrictions scale with demonstrated risk and are revisited as signals change.

---

## 12) Open questions
- How to operationalize “credible, imminent” in existential risk without collapsing privacy?  
- Governance of structural arbiters: who builds, audits, and constrains them?  
- Aggregation boundaries: how narrow must the reference class be for fallback to remain legitimate?  
- Collective harms (e.g., externalities) where no single breach is obvious but aggregate effects violate others’ AA—how to apportion responsibility?

---

## 13) Minimal formalism (sketch)
Let agent \(i\) have choice set \(C\) and state \(s\). Define revealed valence \(V_i(s)\) by AA patterns:

\[ V_i(s) > 0 \iff \exists\; c\in C:\; P_i(c\to s)\ \text{increases under added opportunity/resources} \]
\[ V_i(s) < 0 \iff \exists\; c\in C:\; P_i(c\to s)\ \text{decreases and resources are spent to exit/avoid } s \]

**Sovereignty breach** by agent \(j\): interventions that reduce the feasible set or distort beliefs of \(i\) such that \(V_i\) cannot be expressed via AA (force, fraud, or coercion).

**Forfeiture**: If \(j\) commits a breach, permissible responses \(R\) satisfy proportionality and restoration: minimize future breaches while preserving \(i\)’s sovereignty.

---

## 14) Glossary (quick)
- **AA behavior**: approach/avoidance choices revealing true valence.  
- **Adjoint/structural analysis**: value‑neutral gradient/flow audit.  
- **Aggregate fallback**: provisional, narrow-class inference when signals are absent.  
- **Existential threshold**: scale at which privacy yields to survival.  
- **Forfeiture**: loss of sovereignty claims via violation.

---

*End of draft. Mark sections for revision as the framework evolves.*

